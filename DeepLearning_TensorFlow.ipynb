{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPN+Zz76HyqTL96xdutdhfB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HemaGunasekaran/Basic_Python/blob/master/DeepLearning_TensorFlow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "pcxWthiA5xfR",
        "outputId": "222e013b-e5af-4545-ab03-ddfcf69f521b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-2-cf8053d43031>, line 2)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-cf8053d43031>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    from tensorflow.examples.tutorials.mnist import input data\u001b[0m\n\u001b[0m                                                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.examples.tutorials.mnist import input data\n",
        "\n",
        "mist = input_data.read_data_sets(\"/tmp/data/\",one_hot=True)\n",
        "\n",
        "n nodes hl1 = 500\n",
        "n nodes hl2 = 500\n",
        "n nodes hl3 = 500\n",
        "\n",
        "n classes = 10\n",
        "batch size = 100\n",
        "\n",
        "x = tf.placeholder('float')\n",
        "y = tf.placeholder('float')\n",
        "\n",
        "def neural_network_model(data):\n",
        "  hidden_1_layer = {'weights' :tf.Variable(tf.random normal([784, n_nodes_hl1])),\n",
        "                    'biases':tf. Variable(tf. random_normal([n_nodes_hl1]))}\n",
        "\n",
        "  hidden_2_layer = {'weights' :tf.Variable(tf.random normal([n_nodes_hl1, n_nodes_hl2])),\n",
        "                    'biases':tf. Variable(tf. random_normal([n_nodes_hl2]))}\n",
        "\n",
        "  hidden_3_layer = {'weights' :tf.Variable(tf.random normal([n_nodes_hl2, n_nodes_hl3])),\n",
        "                    'biases':tf. Variable(tf. random_normal([n_nodes_hl3]))}\n",
        "\n",
        "  output_layer = {'weights' :tf.Variable(tf.random normal([n_nodes_hl3, n_classes])),\n",
        "                    'biases':tf. Variable(tf. random_normal([n_classes]))}\n",
        "  l1 = tf.add(tf.matmul(data, hidden_1_layer['weights']),hidden_1_layer['biases'])\n",
        "  l1 = tf.nn.relu(l1)\n",
        "  l2 = tf.add(tf.matmul(data, hidden_2_layer['weights']),hidden_2_layer['biases'])\n",
        "  l2 = tf.nn.relu(l2)\n",
        "  l2 = tf.add(tf.matmul(data, hidden_3_layer['weights']),hidden_3_layer['biases'])\n",
        "  l2 = tf.nn.relu(l3)\n",
        "\n",
        "  output = tf.matmul(l3, output layer['weights']) + output layer[' biases']\n",
        "\n",
        "  return output\n",
        "\n",
        "def train_neural_network(x):\n",
        "  prediction = neural_network_model(x)\n",
        "  cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(prediction, y) )\n",
        "  optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
        "  hm_epochs = 10\n",
        "  with tf.Session() as sess:\n",
        "      sess.run(tf.initialize_all_variables())\n",
        "      for epoch in hm_epochs:\n",
        "          epoch loss = 0\n",
        "          for_in range(int(mnist.train.num_examples/batch size)):\n",
        "            epoch_x, epoch_y = mnist.train.next_batch(batch_size)\n",
        "            _,c = sess.run([optimizer, cost], feed_dict = {x: epoch_x, y: epoch_y})\n",
        "            epoch_loss += c\n",
        "          print('Epoch',epoch,'completed out of',hm_epochs,'loss:'epoch_loss)\n",
        "      correct = tf.equal(tf.argmax(prediction,1), tf.argmax(y,1))\n",
        "      accuracy = tf.reduce_mean(tf.cast(correct,'float'))\n",
        "      print ('Accuracy: ',accuracy.eval({x:mnist.test.images, y:mnist.test.labels}))\n",
        "\n",
        "train_neural_network(x)"
      ]
    }
  ]
}